{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.windows import Window\n",
    "import geopandas as gpd\n",
    "from shapely.ops import unary_union\n",
    "from sklearn.model_selection import train_test_split, class_weight\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from glob import glob\n",
    "from random import sample, choice, uniform\n",
    "from skimage.transform import rotate\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 1. USER PARAMETERS\n",
    "# -----------------------------------------------------------------------------\n",
    "PATCH_SIZE    = 32\n",
    "HALF_PATCH    = PATCH_SIZE // 2\n",
    "CLASS_INDICES = {'Sand': 0, 'SAV': 1}\n",
    "NUM_CLASSES   = len(CLASS_INDICES)\n",
    "BATCH_SIZE    = 32\n",
    "EPOCHS        = 5\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "TRAIN_MOSAIC  = r\"C:\\Users\\00097030\\Git\\WA-coast-SAV\\Data\\Mosaic\\Mosaic_clip.tif\"\n",
    "PTS_SHP       = r\"C:\\Users\\00097030\\Git\\WA-coast-SAV\\Data\\BOSS\\BOSS_update.shp\"\n",
    "EXTENT_SHP    = r\"C:\\Users\\00097030\\Git\\WA-coast-SAV\\Data\\extent\\generalised_extent_update.shp\"\n",
    "PATCH_DIR     = r\"C:\\Users\\00097030\\Git\\WA-coast-SAV\\Data\\image_patches\"\n",
    "PREDICT_IMG   = r\"C:\\Users\\00097030\\Git\\WA-coast-SAV\\Data\\Mosaic\\kndavi_50JLL_clip.tif\"\n",
    "MODEL_DIR     = r\"C:\\Users\\00097030\\Git\\WA-coast-SAV\\Data\\models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 2. EXTRACT 1-BAND PATCHES AROUND Labeled Points\n",
    "# -----------------------------------------------------------------------------\n",
    "# - Clip the mosaic to the study extent\n",
    "extent_geom = unary_union(gpd.read_file(EXTENT_SHP).geometry)\n",
    "with rasterio.open(TRAIN_MOSAIC) as src:\n",
    "    clipped, transform = mask(src, [extent_geom], crop=True, indexes=[1])\n",
    "    base_profile = src.profile\n",
    "\n",
    "# - Update metadata for fixed-size, single-band patches\n",
    "patch_profile = base_profile.copy()\n",
    "patch_profile.update({\n",
    "    'height': PATCH_SIZE,\n",
    "    'width': PATCH_SIZE,\n",
    "    'count': 1,\n",
    "    'dtype': clipped.dtype\n",
    "})\n",
    "\n",
    "# - Split points into training/validation\n",
    "points = gpd.read_file(PTS_SHP)\n",
    "points = points[points['Class'].isin(CLASS_INDICES)]\n",
    "train_pts, val_pts = train_test_split(\n",
    "    points, test_size=0.2, stratify=points['Class'], random_state=0\n",
    ")\n",
    "\n",
    "# - Create output folders\n",
    "for split, subset in ((\"train\", train_pts), (\"val\", val_pts)):\n",
    "    for cls in CLASS_INDICES:\n",
    "        os.makedirs(os.path.join(PATCH_DIR, split, cls), exist_ok=True)\n",
    "\n",
    "    # - Extract and save each patch\n",
    "    for idx, row in subset.iterrows():\n",
    "        x, y = row.geometry.x, row.geometry.y\n",
    "        col, row_i = map(int, (~transform) * (x, y))\n",
    "        window = Window(col-HALF_PATCH, row_i-HALF_PATCH, PATCH_SIZE, PATCH_SIZE)\n",
    "\n",
    "        # skip if patch would go outside the raster\n",
    "        if (window.col_off < 0 or window.row_off < 0 or\n",
    "            window.col_off + window.width  > clipped.shape[2] or\n",
    "            window.row_off + window.height > clipped.shape[1]):\n",
    "            continue\n",
    "\n",
    "        patch = clipped[0,\n",
    "                        int(window.row_off):int(window.row_off + window.height),\n",
    "                        int(window.col_off):int(window.col_off + window.width)]\n",
    "\n",
    "        out_meta = patch_profile.copy()\n",
    "        out_meta.update({'transform': rasterio.windows.transform(window, transform)})\n",
    "        out_fp = os.path.join(PATCH_DIR, split, row['Class'], f\"{split}_{idx}.tif\")\n",
    "\n",
    "        with rasterio.open(out_fp, 'w', **out_meta) as dst:\n",
    "            dst.write(patch[np.newaxis, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 3.MEAN & STD \n",
    "# -----------------------------------------------------------------------------\n",
    "train_files = glob(os.path.join(PATCH_DIR, \"train\", \"*\", \"*.tif\"))\n",
    "sum_, sum_sq, cnt = 0.0, 0.0, 0\n",
    "\n",
    "for fp in train_files:\n",
    "    with rasterio.open(fp) as src:\n",
    "        band = src.read(1, masked=True)\n",
    "    values = band.compressed().astype(np.float64)\n",
    "    sum_   += values.sum()\n",
    "    sum_sq += (values**2).sum()\n",
    "    cnt    += values.size\n",
    "\n",
    "MEAN = sum_ / cnt\n",
    "VAR  = sum_sq / cnt - MEAN**2\n",
    "STD  = float(np.sqrt(max(VAR, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.75, 1: 1.5}\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# . COMPUTE CLASS WEIGHTS TO HANDLE IMBALANCE\n",
    "# -----------------------------------------------------------------------------\n",
    "#labels = np.array([\n",
    "#    CLASS_INDICES[os.path.basename(os.path.dirname(f))]\n",
    "#    for f in train_files\n",
    "#])\n",
    "#cw = class_weight.compute_class_weight(\"balanced\",\n",
    "#                                       classes=np.unique(labels),\n",
    "#                                       y=labels)\n",
    "#CLASS_WEIGHTS = {i: w for i, w in enumerate(cw)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 4. SIMPLE GENERATOR \n",
    "# -----------------------------------------------------------------------------\n",
    "def generator(files, augment=False):\n",
    "    while True:\n",
    "        batch = sample(files, BATCH_SIZE)\n",
    "        X, Y = [], []\n",
    "        for fp in batch:\n",
    "            with rasterio.open(fp) as src:\n",
    "                img = src.read(1, masked=True).filled(MEAN).astype(np.float32)\n",
    "            img = (img - MEAN) / (STD + 1e-6)\n",
    "            if augment:\n",
    "                if choice([True, False]):\n",
    "                    img = np.fliplr(img)\n",
    "                if choice([True, False]):\n",
    "                    img = np.flipud(img)\n",
    "                angle = uniform(-45, 45)\n",
    "                img = rotate(img, angle, mode='reflect', preserve_range=True)\n",
    "            cls = os.path.basename(os.path.dirname(fp))\n",
    "            X.append(img[..., np.newaxis])\n",
    "            Y.append(CLASS_INDICES[cls])\n",
    "        yield np.stack(X), to_categorical(Y, NUM_CLASSES)\n",
    "\n",
    "train_gen = generator(train_files, augment=True)\n",
    "val_files  = glob(os.path.join(PATCH_DIR, \"val\", \"*\", \"*.tif\"))\n",
    "val_gen    = generator(val_files, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.9352 - categorical_accuracy: 0.6094\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.67188, saving model to C:\\Users\\00097030\\Git\\WA-coast-SAV\\Data\\models\\dense_sav_01-0.672.h5\n",
      "10/10 [==============================] - 18s 699ms/step - loss: 0.9352 - categorical_accuracy: 0.6094 - val_loss: 0.7022 - val_categorical_accuracy: 0.6719\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6515 - categorical_accuracy: 0.7219\n",
      "Epoch 2: val_categorical_accuracy improved from 0.67188 to 0.75000, saving model to C:\\Users\\00097030\\Git\\WA-coast-SAV\\Data\\models\\dense_sav_02-0.750.h5\n",
      "10/10 [==============================] - 4s 355ms/step - loss: 0.6515 - categorical_accuracy: 0.7219 - val_loss: 0.6607 - val_categorical_accuracy: 0.7500\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6002 - categorical_accuracy: 0.7156\n",
      "Epoch 3: val_categorical_accuracy did not improve from 0.75000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.6002 - categorical_accuracy: 0.7156 - val_loss: 0.8532 - val_categorical_accuracy: 0.7344\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5443 - categorical_accuracy: 0.7531\n",
      "Epoch 4: val_categorical_accuracy did not improve from 0.75000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.5443 - categorical_accuracy: 0.7531 - val_loss: 0.8038 - val_categorical_accuracy: 0.6875\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5592 - categorical_accuracy: 0.7250\n",
      "Epoch 5: val_categorical_accuracy improved from 0.75000 to 0.76562, saving model to C:\\Users\\00097030\\Git\\WA-coast-SAV\\Data\\models\\dense_sav_05-0.766.h5\n",
      "10/10 [==============================] - 3s 294ms/step - loss: 0.5592 - categorical_accuracy: 0.7250 - val_loss: 0.6146 - val_categorical_accuracy: 0.7656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b08b8ea740>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 5. MODEL TRAINING\n",
    "# -----------------------------------------------------------------------------\n",
    "input_tensor = Input((PATCH_SIZE, PATCH_SIZE, 1))\n",
    "base_model   = DenseNet201(include_top=False, weights=None, input_tensor=input_tensor)\n",
    "x            = GlobalAveragePooling2D()(base_model.output)\n",
    "output       = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "model        = Model(base_model.input, output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['categorical_accuracy']\n",
    ")\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    os.path.join(MODEL_DIR, \"dense_sav_{epoch:02d}-{val_categorical_accuracy:.3f}.h5\"),\n",
    "    monitor='val_categorical_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "earlystop_cb  = EarlyStopping(\n",
    "    monitor='val_categorical_accuracy',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "tensorboard_cb = TensorBoard(log_dir='./logs')\n",
    "\n",
    "steps_per_epoch   = len(train_files) // BATCH_SIZE\n",
    "validation_steps  = len(val_files)   // BATCH_SIZE\n",
    "\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint_cb, earlystop_cb, tensorboard_cb]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferring rows: 100%|██████████| 544/544 [02:24<00:00,  3.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 6. SINGLE-BAND pred\n",
    "# -----------------------------------------------------------------------------\n",
    "with rasterio.open(PREDICT_IMG) as src:\n",
    "    img   = src.read(1, masked=True).filled(MEAN).astype(np.float32)\n",
    "    meta  = src.profile.copy()\n",
    "\n",
    "H0,W0 = img.shape\n",
    "pad   = HALF\n",
    "img_p = np.pad(img,((pad,pad),(pad,pad)),mode='reflect')\n",
    "img_p = (img_p-MEAN)/(STD+1e-6)\n",
    "\n",
    "prob = np.zeros((H0,W0,NUM_CLASSES),dtype=np.float32)\n",
    "buf  = np.zeros((W0,PATCH_SIZE,PATCH_SIZE,1),dtype=np.float32)\n",
    "\n",
    "for i in tqdm(range(pad,pad+H0),desc=\"Inferring rows\"):\n",
    "    for j in range(pad,pad+W0):\n",
    "        buf[j-pad,...,0] = img_p[i-pad:i+pad,j-pad:j+pad]\n",
    "    pr = model.predict(buf, batch_size=256, verbose=0)\n",
    "    prob[i-pad,:,:] = pr\n",
    "\n",
    "label    = np.argmax(prob,axis=-1).astype(np.uint8)\n",
    "prob_max = prob.max(axis=-1).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_label_fp  = os.path.join(\"Data\",\"Mosaic\",\"classified_label_2.tif\")\n",
    "out_prob_fp  = os.path.join(\"Data\",\"Mosaic\",\"classified_prob_2.tif\")\n",
    "# write outputs\n",
    "meta.update(count=1,dtype='uint8')\n",
    "with rasterio.open(out_label_fp,'w',**meta) as dst: dst.write(label,1)\n",
    "meta.update(dtype='float32')\n",
    "with rasterio.open(out_prob_fp,'w',**meta) as dst: dst.write(prob_max,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
